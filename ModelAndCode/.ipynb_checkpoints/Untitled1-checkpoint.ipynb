{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (mtcnn.py, line 147)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"./mtcnn-master/mtcnn/mtcnn.py\"\u001b[0;36m, line \u001b[0;32m147\u001b[0m\n\u001b[0;31m    def __init__(self, pad_result: tuple=None, width=0, height=0):\u001b[0m\n\u001b[0m                                 ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "print(\"hello\")\n",
    "import sys\n",
    "sys.path.append('./mtcnn-master')\n",
    "from mtcnn.mtcnn import MTCNN\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "from keras.models import Model\n",
    "from PIL import Image\n",
    "\n",
    "from inception_resnet_v1 import *\n",
    "\n",
    "detector = MTCNN()\n",
    "\n",
    "def l2_normalize(x):\n",
    " return x / np.sqrt(np.sum(np.multiply(x, x)))\n",
    "\n",
    "model = InceptionResNetV1()\n",
    "model.load_weights('model/facenet_weights.h5')\n",
    "\n",
    "stud_img_src = \"DataSet/batch/students/stud_img_src/\"\n",
    "\n",
    "# SET THIS VARIABLE BEFORE RUNNING CODE\n",
    "\n",
    "class_strength = 13\n",
    "\n",
    "dim = (160, 160)\n",
    "\n",
    "print(\"hello\")\n",
    "\n",
    "files = os.listdir(stud_img_src)\n",
    "\n",
    "for file_name in files:\n",
    "\tstud_pics = stud_img_src + file_name\n",
    "\tfor j in range(5):\n",
    "\t\tpic = stud_pics + \"/{}.jpg\".format(j+1)\n",
    "\t\tpic_cv = cv2.imread(pic)\n",
    "\t\tface = detector.detect_faces(pic_cv)\n",
    "\t\tif len(face)!=0:\n",
    "\t\t\tface_coordinate = face[0][\"box\"]\n",
    "\t\t\timageObject = Image.open(pic)\n",
    "\t\t\tcropped = imageObject.crop((face_coordinate[0],face_coordinate[1],face_coordinate[0]+ face_coordinate[2],face_coordinate[1]+face_coordinate[3]))\n",
    "\t\t\tcropped = np.array(cropped)\n",
    "\t\t\tresized_pic = cv2.resize(cropped,dim,interpolation=cv2.INTER_AREA)\n",
    "\t\t\t# cv2.imwrite(\"face_{}.jpg\".format(j+1), resized_pic)\n",
    "\t\t\treshaped_pic = resized_pic.reshape(1,resized_pic.shape[0],resized_pic.shape[1],resized_pic.shape[2])\n",
    "\t\t\tpic_representation = l2_normalize(model.predict(reshaped_pic)[0,:])\n",
    "\t\t\tnp.save(stud_pics + \"/{}.npy\".format(j+1), pic_representation)\n",
    "\t\telse:\n",
    "\t\t\tresized_pic = cv2.resize(pic_cv,dim,interpolation=cv2.INTER_AREA)\n",
    "\t\t\t# cv2.imwrite(\"face_{}.jpg\".format(j+1), resized_pic)\n",
    "\t\t\treshaped_pic = resized_pic.reshape(1,resized_pic.shape[0],resized_pic.shape[1],resized_pic.shape[2])\n",
    "\t\t\tpic_representation = l2_normalize(model.predict(reshaped_pic)[0,:])\n",
    "\t\t\tnp.save(stud_pics + \"/{}.npy\".format(j+1), pic_representation)\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
